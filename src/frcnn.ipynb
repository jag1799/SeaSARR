{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faster R-CNN Analysis\n",
    "\n",
    "This notebook is an analysis of the performance of various layer additions to the Faster R-CNN model as used in Pytorch.  The dataset used is the SARscope dataset found at the below link.  The objective is to determine whether proposed image processing methods would increase model performance on Synthetic Aperture Radar data of maritime vessels.\n",
    "\n",
    "Dataset: https://www.kaggle.com/datasets/kailaspsudheer/sarscope-unveiling-the-maritime-landscape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 - Workspace Preparation\n",
    "\n",
    "To ensure that the user can run this notebook without issue, please do the following:\n",
    "\n",
    "1. Ensure your Python installtion is 3.8.10 or higher.\n",
    "2. You are using the pip3 package manager.\n",
    "3. Run the below installation steps. These are all the packages used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install torch\n",
    "!pip3 install torchvision\n",
    "!pip3 install torchmetrics\n",
    "!pip3 install kagglehub\n",
    "!pip3 install json\n",
    "!pip3 install matplotlib\n",
    "!pip3 install cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2 - Dataset Loading\n",
    "\n",
    "The user has two options for initializing their data.  They can either provide a path to a local copy of the dataset folder or they can load it using the Kagglehub module.  To choose the local path option, simply provide the absolute path to the 'SARscope' folder and no lower.  To choose the Kagglehub option, leave the 'path' variable as 'None'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility Imports\n",
    "import json\n",
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "\n",
    "# Data Handling Imports\n",
    "import cv2\n",
    "import kagglehub\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Model & Metric Imports\n",
    "import torch\n",
    "import torchmetrics\n",
    "import torchvision\n",
    "\n",
    "project_path = pathlib.Path.cwd().parent.resolve()\n",
    "print(f\"Project path: {project_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.1: Note on Kagglehub\n",
    "\n",
    "Kagglehub does not natively support downloading to specific directories on the user's file system.  It instead downloads it to a cache folder, which may vary between users.  Thus, all downloads will move the data folder to the included data directory under the '*/data/kaggle/*' folder for consistency.\n",
    "\n",
    "If you have an error, this is likely due to the `shutil.move()` command failing because it sees the dataset still cached.  To counteract this, `cd` into the cache directory that is printed in the output and delete the entire data folder.  Then run this block again.\n",
    "\n",
    "Once the dataset is downloaded, you can either continue or change the `data_path` variable from `None` to the *SARscope* folder's absolute path which will avoid re-downloading everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = None # Leave None to download data through Kagglehub.  Otherwise, provide the path to your dataset.\n",
    "\n",
    "if data_path is None:\n",
    "    # Create the Kaggle directory to move the downloaded data to\n",
    "    kaggle_path = os.path.join(project_path, \"data\", \"kaggle\")\n",
    "\n",
    "    if not os.path.exists(kaggle_path):\n",
    "        os.makedirs(kaggle_path, exist_ok=True)\n",
    "\n",
    "    # Download the SARscope dataset from Kaggle\n",
    "    try:\n",
    "        cached_path = kagglehub.dataset_download(\"kailaspsudheer/sarscope-unveiling-the-maritime-landscape\")\n",
    "    except:\n",
    "        raise LookupError(\"Unable to download SEAscope dataset.\")\n",
    "\n",
    "    # Get the absolute path and move it.\n",
    "    cached_path = os.path.abspath(os.path.join(cached_path, \"SARscope\"))\n",
    "\n",
    "    print(f\"Moving cached dataset from directory {cached_path} to {kaggle_path}\")\n",
    "    shutil.move(cached_path, kaggle_path)\n",
    "\n",
    "    data_path = os.path.join(kaggle_path, \"SARscope\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Using path to dataset: {data_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3 - Data Visualization\n",
    "\n",
    "Below, we visualize a few randomly selected images throughout the training dataset as examples of the different types of images the model will encounter and to ensure the annotations are working as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = os.listdir(os.path.join(data_path, \"train\"))\n",
    "\n",
    "# Extract the annotation file\n",
    "train_annotation_file = [x for x in train_files if x.endswith(\".json\")][0]\n",
    "train_annotation_file = os.path.join(data_path, \"train\", train_annotation_file)\n",
    "\n",
    "# Remove the annotation file from the list of image files and add the absolute paths\n",
    "train_files = [x for x in train_files if not x.endswith(\".json\")]\n",
    "train_files = list(map(lambda x: os.path.join(data_path, \"train\", x), train_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample = random.sample(train_files, 3)\n",
    "\n",
    "with open(train_annotation_file, 'r') as fAnn:\n",
    "    annotations = json.load(fAnn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
