{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Overview\n",
    "\n",
    "This notebook includes a general overview of the dataset by (1) preparing your workspace to use the dataset in the COCO format, (2) visualizing a few images from one of the datasets for information purposes, and (3) conducting an analysis on modifications made to the Faster R-CNN model.  The dataset used is the SARscope dataset found at the below link.  The objective of this project is to determine whether proposed image processing methods would increase the performance of different models on Synthetic Aperture Radar data of maritime vessels.\n",
    "\n",
    "Dataset: https://www.kaggle.com/datasets/kailaspsudheer/sarscope-unveiling-the-maritime-landscape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 - Workspace Preparation\n",
    "\n",
    "To ensure that the user can run this notebook without issue, please do the following:\n",
    "\n",
    "1. Ensure your Python installtion is 3.8.10 or higher.\n",
    "2. You are using the pip3 package manager.\n",
    "3. Run the below installation steps. These are all the packages used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip3 install torch\n",
    "# %pip3 install torchvision\n",
    "# %pip3 install torchmetrics\n",
    "# %pip3 install kagglehub\n",
    "# %pip3 install json\n",
    "# %pip3 install matplotlib\n",
    "# %pip3 install cv2\n",
    "# %pip install pycocotools\n",
    "# %pip install utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility Imports\n",
    "import os, sys\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Data Handling Imports\n",
    "from SeaSarFRCNN import SeaSarFRCNN\n",
    "from ModelWorker import ModelWorkerFRCNN\n",
    "from WorkspaceManager import WorkspaceManager\n",
    "\n",
    "# Model and Model Utility Imports\n",
    "import torchvision\n",
    "import torch\n",
    "from frcnn_models import CannyFRCNN, RobinsonFRCNN, RobinsonCompass\n",
    "\n",
    "project_path = pathlib.Path.cwd().parent.resolve()\n",
    "print(f\"Project path: {project_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2 - Dataset Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.1: Note on Kagglehub\n",
    "\n",
    "Kagglehub does not natively support downloading to specific directories on the user's file system.  It instead downloads it to a cache folder, which may vary between users.  Thus, the below script moves all downloads will move the dataset folder to the included */data* folder in this repo.\n",
    "\n",
    "If you have an error, this is likely due to the `shutil.move()` command failing because it sees the dataset still cached.  To counteract this, `cd` into the cache directory that is printed in the output and delete the entire data folder.  Then run this block again.  See Section 2.2 and the below code block comments for additional information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.2: Deleting the Cache\n",
    "\n",
    "To re-download the dataset, you need to remove both the formatted folder in this repo's data directory (the *kaggle* folder) and the *kailaspsudheer* folder in the cache.\n",
    "\n",
    "I recommend you run the *WorkspaceManager* setup block below with *clear_cache* off first, then manually delete it if you need to.  After you know where your cache is and confirm it's deleting the right directory, you can turn it on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_builder = WorkspaceManager()\n",
    "workspace_builder.run_setup()\n",
    "\n",
    "if not os.path.exists(workspace_builder._data_path):\n",
    "    raise FileNotFoundError(f\"Not able to find data directory at path: {workspace_builder._data_path}\")\n",
    "else:\n",
    "    print(f\"Using data path: {workspace_builder._data_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3 - Data Visualization\n",
    "\n",
    "Below, we visualize a few randomly selected images throughout the validation dataset as examples of the different types of images the models will encounter and to ensure the annotations are working as expected.  All targets have the same category Id and category name: (1, \"ship\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Path retrieval\n",
    "tester_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "train_annotations = os.path.join(workspace_builder._data_path, \"annotations\", \"train_annotations.coco.json\")\n",
    "train_images = os.path.join(workspace_builder._data_path, \"train\")\n",
    "\n",
    "train_data = SeaSarFRCNN(train_images, train_annotations, tester_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display 3 randomly selected images throughout the validation dataset with their annotations.\n",
    "for i in range(3):\n",
    "    train_data._random_image()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4 - Faster R-CNN\n",
    "\n",
    "This section begins the analysis of different layer additions and modifications to the Faster R-CNN model.  Each section contains the following sub-sections for reference:\n",
    "\n",
    "1. Data Preparation\n",
    "2. Model Construction\n",
    "3. Training\n",
    "4. Testing & Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4.1 - Baseline FRCNN\n",
    "\n",
    "This section is to establish the baseline performance of an unmodified FRCNN model on our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 4.1.1 - Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up train dataloader\n",
    "train_data = torchvision.datasets.wrap_dataset_for_transforms_v2(train_data, target_keys=(\"boxes\", \"labels\"))\n",
    "train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=1, shuffle=False, collate_fn=train_data._packager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_annotations = os.path.join(workspace_builder._data_path, \"annotations\", \"valid_annotations.coco.json\")\n",
    "validation_images = os.path.join(workspace_builder._data_path, \"valid\")\n",
    "validation_data = SeaSarFRCNN(validation_images, validation_annotations, transform=tester_transforms)\n",
    "validation_data = torchvision.datasets.wrap_dataset_for_transforms_v2(validation_data, target_keys=(\"boxes\", \"labels\"))\n",
    "validation_dataloader = torch.utils.data.DataLoader(validation_data, batch_size=1, shuffle=False, collate_fn=validation_data._packager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 4.1.2 - Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the baseline model\n",
    "frcnn = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "input_features = frcnn.roi_heads.box_predictor.cls_score.in_features\n",
    "frcnn.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(input_features, 2)\n",
    "\n",
    "# Build the loss function and optimizer\n",
    "optimizer = torch.optim.Adam(frcnn.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 4.1.3 - Baseline Training & Validation\n",
    "\n",
    "When running training, be advised that you may need to close other programs, completely kill your Jupyter Kernel, or restart VSCode.  FRCNN and Pytorch consume significant amounts of memory per run and remain allocated in the background on your GPU.  After enough times running train/validation cells, the program will fail saying CUDA is out of memory.  This is when you must either manually kill background programs from the terminal or restart VSCode.  Below are the instructions to determine which programs to kill.\n",
    "\n",
    "**NOTE**: These instructions were written for Ubuntu Linux 20.04.  Your steps may differ slightly.\n",
    "\n",
    "1. Open a terminal window\n",
    "2. Assuming you have CUDA set up, enter the \"*nvidia-smi*\" command.  This will display all processes currently using your GPU.\n",
    "3. Run *sudo fuser -v /dev/nvidia\\**.  This will display another list of process also using your GPU, including the owner of said process.\n",
    "    - This step is to differentiate between your processes and system processes.  \n",
    "    - **DO NOT EVER KILL A SYSTEM PROCESS USING THESE STEPS. IF IT IS CAUSING PROBLEMS, RESTART YOUR COMPUTER AND THIS CAN SAFELY REFRESH ALL PROCESSES USING YOUR GPU.**\n",
    "4. Identify all processes owned by you and get their PIDs.\n",
    "5. Refer back to the *nvidia-smi* table on which PID is consuming the most memory.\n",
    "6. Do one of the following:\n",
    "    - If possible, close the process normally like a Firefox window.\n",
    "    - Run *sudo kill -9 \"your_PID\"*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do training and validation\n",
    "worker = ModelWorkerFRCNN(optimizer=optimizer, frcnn=frcnn, quiet=False)\n",
    "worker.train(train_dataloader, 1, [3736])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run validation\n",
    "worker.validation(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 4.1.4 - Baseline Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = os.path.join(workspace_builder._data_path, \"test\")\n",
    "test_annotations = os.path.join(workspace_builder._data_path, \"annotations\", \"test_annotations.coco.json\")\n",
    "test_data = SeaSarFRCNN(test_images, test_annotations, transform=tester_transforms)\n",
    "test_data = torchvision.datasets.wrap_dataset_for_transforms_v2(test_data, target_keys=(\"boxes\", \"labels\"))\n",
    "test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=True, collate_fn=test_data._packager, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worker.model_test(test_dataloader, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5 - Canny FRCNN\n",
    "\n",
    "In this section, we utilize the OpenCV implementation of the Canny algorithm as a preprocessing layer to Faster-RCNN and analyze its performance.  Canny is a popular multi-stage edge detection algorithm designed to a) highlight the edges of all objects within an image and b) remove anything between different edges. \n",
    "\n",
    "In using this algorithm, we hypothesize that FRCNN will achieve better performance on more complex images since much of the noise of non-targets is removed and only the outline of the edges is considered.  By training on a ship's outline, which is relatively consistent regardless of ship sizes, we expect the model to identify targets in areas that previously had significant amounts of noise, such as docks, inclement weather, and other confusers.\n",
    "\n",
    "## 5.1 - Canny Overview\n",
    "\n",
    "The Canny pipeline includes three steps:\n",
    "\n",
    "1. **Noise Reduction**: Use Gaussian Blurring on the entire image to reduce noise surrounding edges that may lead to false positives.\n",
    "2. **Gradient Intensity**: It then uses the Sobel kernel (another Edge Detection method) in the X and Y directions to determine the gradient magnitude. Then it uses a formula to extract the gradient direction of individual pixels.\n",
    "3. **Non-Maximum Suppression**: Once edges are proposed, NMS is used to remove any pixels that may be a false positive edge.\n",
    "\n",
    "For more details on the Canny algorithm, OpenCV's documentation has a good explanation of the topic: https://docs.opencv.org/4.x/da/d22/tutorial_py_canny.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 - Data Analysis\n",
    "\n",
    "Below, we provide an example of how Canny can assist the detection models by remove noise and highlight ship outlines.  In the original image, targets are intermingled with what appears to be either inclement weather or some other noise type.  In the succeeding subplot, we can see those inclement weather spots are fully removed while the outline of the targets are retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_dataset = SeaSarFRCNN(train_images, train_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, target = examples_dataset._get_image(3270, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_image = cv2.GaussianBlur(np.array(image), ksize=(5, 5), sigmaX=2.0)\n",
    "canny_image = cv2.Canny(gaussian_image, 200, 100)\n",
    "examples_dataset.show_edited_subplot([image, gaussian_image, canny_image], [\"Original\", \"Gaussian Blurred\", \"Post-Canny\"], \"\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 - False Positives\n",
    "\n",
    "As shown in 5.3, setting the Canny thresholds to (200, 100) began yield positive results like the image above.  However, there are some drawbacks to using static threshold values. Setting the threshold too high can remove key target details or even entire targets. Using a value too small will not remove enough noise and can reduce model performance.  As we see in the below figures, (200, 100) is not a high enough threshold to clear much of the noise from the shoreline, inevitably leading to misclassifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, target = examples_dataset._get_image(2732, get_image=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_image = cv2.GaussianBlur(np.array(image), ksize=(5, 5), sigmaX=2.0)\n",
    "canny_image = cv2.Canny(gaussian_image, 200, 100)\n",
    "examples_dataset.show_edited_subplot([image, gaussian_image, canny_image], [\"Original\", \"Gaussian Blurred\", \"Post-Canny\"], \"\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5.3 Model Construction and Training\n",
    "\n",
    "In this section, we build the CannyFRCNN model.  We use a 3x3 kernel and standard deviation of 1 for Gaussian Blurring. For Canny, using 200 or higher for threshold 1 and 100 or higher for threshold 2 began to show good results on most images as this is when noise began being filtered out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canny_model = CannyFRCNN(frcnn, 'cuda', (3, 3), 1.0, 200, 100)\n",
    "worker = ModelWorkerFRCNN(optimizer, canny_model, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worker.train(train_dataloader, num_epochs=1, indices_to_skip=[3736])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 6 - Robinson Compass FRCNN\n",
    "\n",
    "This section uses the Robinson Compass edge detection algorithm in the same manner as the aforementioned Canny Algorithm.  The algorithm seeks to highlight target edges based on some threshold using eight different kernels highlighting edges based on the eight primary compass directions.  We anticipate comparable results to the Canny method since RC will consider edges from eight different directions across a gradient image rather than the approach Canny takes. \n",
    "\n",
    "## 6.1 - Robinson Compass Overview\n",
    "\n",
    "Robinson Compass relies on using kernels that highlight edges focused on a specified direction using Compass directions to select them.  There are eight kernels corresponding to eight compass directions.\n",
    "\n",
    "The Robinson Compass implementation was inspired from the following link: https://medium.com/@erhan_arslan/exploring-edge-detection-in-python-3-compass-edge-detector-edf8721a7825"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rob_comp = RobinsonCompass((3, 3), 1, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 - Data Overview\n",
    "\n",
    "Below, we can see that some images are easier to extract primary targets.  The target edges are thick and resemble blobs more, likely making it easier for the FRCNN model to detect them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, target = examples_dataset._get_image(3270, True, False)\n",
    "image = np.array(image)\n",
    "edges = rob_comp.get_detections(image)\n",
    "plt.imshow(edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1 - False Positives\n",
    "\n",
    "Like the Canny method, the compass method also suffers from the thresholding issue.  Below the same image shows even more false edges in the image.  This in turn may prove our original hypothesis wrong about RC since there will be far more confuser information present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, target = examples_dataset._get_image(2732, get_image=True)\n",
    "image = np.array(image)\n",
    "edges = rob_comp.get_detections(image)\n",
    "plt.imshow(edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 - Model Construction and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rob_comp_model = RobinsonFRCNN(frcnn, 'cuda', (3, 3), 1, 500)\n",
    "worker = ModelWorkerFRCNN(optimizer, rob_comp_model, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worker.train(train_dataloader, num_epochs=1, indices_to_skip=[3736])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
