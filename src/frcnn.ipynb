{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Overview\n",
    "\n",
    "This notebook includes a general overview of the dataset by (1) preparing your workspace to use the dataset in the COCO format, (2) visualizing a few images from one of the datasets for information purposes, and (3) conducting an analysis on modifications made to the Faster R-CNN model.  The dataset used is the SARscope dataset found at the below link.  The objective of this project is to determine whether proposed image processing methods would increase the performance of different models on Synthetic Aperture Radar data of maritime vessels.\n",
    "\n",
    "Dataset: https://www.kaggle.com/datasets/kailaspsudheer/sarscope-unveiling-the-maritime-landscape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 - Workspace Preparation\n",
    "\n",
    "To ensure that the user can run this notebook without issue, please do the following:\n",
    "\n",
    "1. Ensure your Python installtion is 3.8.10 or higher.\n",
    "2. You are using the pip3 package manager.\n",
    "3. Run the below installation steps. These are all the packages used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip3 install torch\n",
    "# %pip3 install torchvision\n",
    "# %pip3 install torchmetrics\n",
    "# %pip3 install kagglehub\n",
    "# %pip3 install json\n",
    "# %pip3 install matplotlib\n",
    "# %pip3 install cv2\n",
    "# %pip install pycocotools\n",
    "# %pip install utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility Imports\n",
    "import os, sys\n",
    "import pathlib\n",
    "\n",
    "# Data Handling Imports\n",
    "from SeaSarFRCNN import SeaSarFRCNN\n",
    "from ModelWorker import ModelWorkerFRCNN\n",
    "from WorkspaceManager import WorkspaceManager\n",
    "\n",
    "# Data & Model Imports\n",
    "import torchvision\n",
    "import torch\n",
    "\n",
    "project_path = pathlib.Path.cwd().parent.resolve()\n",
    "print(f\"Project path: {project_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2 - Dataset Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.1: Note on Kagglehub\n",
    "\n",
    "Kagglehub does not natively support downloading to specific directories on the user's file system.  It instead downloads it to a cache folder, which may vary between users.  Thus, the below script moves all downloads will move the dataset folder to the included */data* folder in this repo.\n",
    "\n",
    "If you have an error, this is likely due to the `shutil.move()` command failing because it sees the dataset still cached.  To counteract this, `cd` into the cache directory that is printed in the output and delete the entire data folder.  Then run this block again.  See Section 2.2 and the below code block comments for additional information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.2: Deleting the Cache\n",
    "\n",
    "To re-download the dataset, you need to remove both the formatted folder in this repo's data directory (the *kaggle* folder) and the *kailaspsudheer* folder in the cache.\n",
    "\n",
    "I recommend you run the *WorkspaceManager* setup block below with *clear_cache* off first, then manually delete it if you need to.  After you know where your cache is and confirm it's deleting the right directory, you can turn it on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_builder = WorkspaceManager()\n",
    "workspace_builder.run_setup()\n",
    "\n",
    "if not os.path.exists(workspace_builder._data_path):\n",
    "    raise FileNotFoundError(f\"Not able to find data directory at path: {workspace_builder._data_path}\")\n",
    "else:\n",
    "    print(f\"Using data path: {workspace_builder._data_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3 - Data Visualization\n",
    "\n",
    "Below, we visualize a few randomly selected images throughout the validation dataset as examples of the different types of images the models will encounter and to ensure the annotations are working as expected.  All targets have the same category Id and category name: (1, \"ship\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Path retrieval\n",
    "tester_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "train_annotations = os.path.join(workspace_builder._data_path, \"annotations\", \"train_annotations.coco.json\")\n",
    "train_images = os.path.join(workspace_builder._data_path, \"train\")\n",
    "\n",
    "train_data = SeaSarFRCNN(train_images, train_annotations, tester_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display 3 randomly selected images throughout the validation dataset with their annotations.\n",
    "for i in range(3):\n",
    "    train_data.show_random_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4 - Faster R-CNN\n",
    "\n",
    "This section begins the analysis of different layer additions and modifications to the Faster R-CNN model.  Each section contains the following sub-sections for reference:\n",
    "\n",
    "1. Data Preparation\n",
    "2. Model Construction\n",
    "3. Training\n",
    "4. Testing & Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4.1 - Baseline FRCNN\n",
    "\n",
    "This section is to establish the baseline performance of an unmodified FRCNN model on our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 4.1.1 - Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up train dataloader\n",
    "train_data = torchvision.datasets.wrap_dataset_for_transforms_v2(train_data, target_keys=(\"boxes\", \"labels\"))\n",
    "train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=1, shuffle=False, collate_fn=train_data._packager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_annotations = os.path.join(workspace_builder._data_path, \"annotations\", \"valid_annotations.coco.json\")\n",
    "validation_images = os.path.join(workspace_builder._data_path, \"valid\")\n",
    "validation_data = SeaSarFRCNN(validation_images, validation_annotations)\n",
    "validation_data = torchvision.datasets.wrap_dataset_for_transforms_v2(validation_data, target_keys=(\"boxes\", \"labels\"))\n",
    "validation_dataloader = torch.utils.data.DataLoader(validation_data, batch_size=1, shuffle=False, collate_fn=validation_data._packager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 4.1.2 - Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the baseline model\n",
    "frcnn = torchvision.models.detection.fasterrcnn_resnet50_fpn()\n",
    "input_features = frcnn.roi_heads.box_predictor.cls_score.in_features\n",
    "frcnn.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(input_features, 2)\n",
    "\n",
    "# Build the loss function and optimizer\n",
    "optimizer = torch.optim.Adam(frcnn.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 4.1.3 - Baseline Training & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do training and validation\n",
    "worker = ModelWorkerFRCNN(train_dataloader=train_dataloader, validation_dataloader=validation_dataloader, optimizer=optimizer, frcnn=frcnn, quiet=False)\n",
    "worker.model_train_val(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
